{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet Demo\n",
    "\n",
    "CS/Math 667 Fall 2018\n",
    "Presented Dec. 3, 2018\n",
    "\n",
    "This demo is using Tensorflow, Docker, Jupyter Notebook, and Imagenet Classes.\n",
    "\n",
    "The requirements.txt, jupyter notebook, Docker Hub link, and example images will be shared so that you may run this example and/or input your own images or url's for classification. \n",
    "\n",
    "Note: Local images can be of any type supported by PIL && matplotlib.\n",
    "\n",
    "Note: URL's can only be jpegs.\n",
    "\n",
    "The model used:\n",
    "(https://storage.googleapis.com/download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v2_fp32_savedmodel_NHWC_jpg.tar.gz)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's begin\n",
    "\n",
    "To start we need the Docker image: \n",
    "more info may be found here https://www.tensorflow.org/serving/\n",
    "in a shell: \n",
    "```bash\n",
    "docker pull tensorflow/serving@sha256:1aaf111b4abb9f2aee618d13f556ab24fee4fff4c44993683772643a7c513b1d\n",
    "```\n",
    "\n",
    "# ImageNet classes: \n",
    "https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\n",
    "Note: imagenet_class_index.json is bundled with this notebook for your convenience. \n",
    "\n",
    "\n",
    "# Python virtual environment:\n",
    "in a shell:\n",
    "```bash\n",
    "python3 -m venv tf_client_venv\n",
    ". ./tf_client_venv/bin/activate\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "\n",
    "# ResNet Model:\n",
    "https://storage.googleapis.com/download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v2_fp32_savedmodel_NHWC_jpg.tar.gz\n",
    "\n",
    "And extract into your homedirectory\n",
    "```bash\n",
    "mkdir -p ~/tmp/resnet\n",
    "curl -s http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v2_fp32_savedmodel_NHWC_jpg.tar.gz | \\\n",
    "tar --strip-components=2 -C $HOME/tmp/resnet -xvz\n",
    "```\n",
    "\n",
    "# Jupyter Notebook\n",
    "This resnet_demo is a Python 3 Juptyer notebook.\n",
    "\n",
    "# Input image or url (jpeg)\n",
    "A few sample images are included with this notebook.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we can start the TensorFlow server and open Jupyter Notebook.\n",
    "\n",
    "We started the virtual environment in the previous cell \n",
    " with the following:\n",
    "```bash\n",
    ". ./tf_client_venv/bin/activate\n",
    "```\n",
    "\n",
    "# Next, we can start the Docker tensorflow/serving image \n",
    "The order of activating the virtual environment or Docker does not matter.\n",
    "However, the virtual environment needs to be activated before \n",
    "running jupyter-notebook.\n",
    "Note: the following command is one line:\n",
    "```bash\n",
    "      docker run --rm -p 8501:8501 --name tfserving_resnet \\\n",
    "      --mount type=bind,source=$HOME/tmp/resnet,target=/models/resnet -e \\\n",
    "      MODEL_NAME=resnet -t tensorflow/serving &\n",
    "```\n",
    "\n",
    "# Now we load Jupyter Notebook:\n",
    "```bash \n",
    "jupter-notebook\n",
    "```\n",
    "\n",
    "# Open the resnet_demo.ipynb\n",
    "You may use the demo to classify your own images. \n",
    "\n",
    "Just replace the input to classify_image() with a local image path:\n",
    "```bash\n",
    "      classify_image(os.path.join(os.environ['HOME'],'/tmp/resnet_demo/lemon.jpg')\n",
    "```\n",
    "\n",
    "or with a url to a jpeg\n",
    "```bash\n",
    "      classify_image('https://www.example.com/lemon.jpg')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import requests\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow, imread\n",
    "import numpy as np\n",
    "from urllib3.util import url\n",
    "from urllib.request import urlopen\n",
    "import io\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# The model being used is \n",
    "# https://storage.googleapis.com/download.tensorflow.org/models/official/20181001_resnet/\n",
    "#    savedmodels/resnet_v2_fp32_savedmodel_NHWC_jpg.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image file reading and classifying\n",
    "#\n",
    "#\n",
    "# Images need to be read and then encoded into base64 \n",
    "# and then placed into a JSON object (as per API).\n",
    "# Python will do this for you if you ask nicely.\n",
    "\n",
    "# Note: The model dictates how the input should be formatted. \n",
    "# So, it is super important to know what the format is in order\n",
    "# to feed it information to classify.\n",
    "\n",
    "\n",
    "\n",
    "# Encode input image into base64 and display the image\n",
    "\n",
    "\n",
    "def display_and_load(filename):\n",
    "    uri = url.parse_url(filename)\n",
    "    if uri.scheme is None:\n",
    "        with open(filename, 'rb') as fd:\n",
    "            encoded_image = base64.b64encode(fd.read()).decode('utf8')\n",
    "        image = imread(filename)\n",
    "    else:\n",
    "        with urlopen(filename) as conn:\n",
    "            data = io.BytesIO(conn.read())\n",
    "            encoded_image = base64.b64encode(data.read()).decode('utf8')\n",
    "            data.seek(0)\n",
    "        image = imread(data, 'jpg')\n",
    "\n",
    "    imshow(image)\n",
    "    return encoded_image\n",
    "\n",
    "\n",
    "\n",
    "# Loads the ImageNet classes dictionary\n",
    "\n",
    "with open(\"/home/linda/deep_residual_learning_project/imagenet_class_index.json\") as fd:\n",
    "    classes_dictionary = json.load(fd)\n",
    "\n",
    "    \n",
    "    \n",
    "# Classifies the input image (local file or jpeg url)\n",
    "\n",
    "def classify_image(filename):\n",
    "    encoded_string = display_and_load(filename)\n",
    "    data = {'instances': [{'b64': encoded_string}]}\n",
    "    r = requests.post('http://localhost:8501/v1/models/resnet:predict', json = data)\n",
    "    predicted_class = r.json()['predictions'][0]['classes']\n",
    "    prediction = classes_dictionary[str(predicted_class - 1)]\n",
    "    print('The predicted class is: {}: {}'.format(predicted_class - 1, prediction)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_image(os.path.join(os.environ['HOME'],'/tmp/resnet_demo/lemon.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_image(os.path.join(os.environ['HOME'],'/tmp/resnet_demo/l0.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_image('https://farm4.staticflickr.com/3218/3054852015_ecb7c51d37_m_d.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_image('https://farm1.staticflickr.com/173/470851368_85fa244783_m_d.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_image('https://farm1.staticflickr.com/153/409287804_543c529cb3_m_d.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_image('https://farm1.staticflickr.com/128/394938875_817edf4eba_m_d.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_image('https://farm1.staticflickr.com/105/271302810_6d3c76ed3d_m_d.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_image('https://farm1.staticflickr.com/46/139492445_6e3b74f881_z_d.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now we have seen one local image and several creative commons images. \n",
    "\n",
    "How about we try to classify some new input(s)?\n",
    "\n",
    "Note: For the live demo, our team showed objects in person and asked the audience to classify \n",
    "the objects and then we asked the model to classify the objects and compared the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_image(os.path.join(os.environ['HOME'],'/tmp/resnet_demo/r0.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_image(os.path.join(os.environ['HOME'],'/tmp/resnet_demo/p1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_image(os.path.join(os.environ['HOME'],'/tmp/resnet_demo/j1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_image(os.path.join(os.environ['HOME'],'/tmp/resnet_demo/l1.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hrmmm... \n",
    "\n",
    "looks like we need to see about getting this book's cover into the labelled dataset.\n",
    "\n",
    "Ok, just one more image to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_image('https://upload.wikimedia.org/wikipedia/commons/f/f9/STOP_sign.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yay, classifying is fun!\n",
    "\n",
    "Now you are ready to use this ResNet demo to classify your own images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This demo was made possible by open source software and creative commons images. \n",
    "\n",
    "# Thanks to all of the open source and creative commons contributors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
